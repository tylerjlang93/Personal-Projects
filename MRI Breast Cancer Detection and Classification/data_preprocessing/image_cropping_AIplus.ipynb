{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\frank\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\frank\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "c:\\Users\\frank\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "c:\\Users\\frank\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seperating images and labels for AI+ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"C:/Users/frank/OneDrive/Desktop/GT_Practicum/data/AI+/Ultrasound-labeled/malignant/\"\n",
    "\n",
    "img_list = glob(os.path.join(data_path, '*/*.jpg'))\n",
    "json_list = glob(os.path.join(data_path, '*/*.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 488\n",
      "Number of jsons: 488\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of images: {}\".format(len(img_list)))\n",
    "print(\"Number of jsons: {}\".format(len(json_list)))\n",
    "\n",
    "assert len(img_list) == len(json_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_des_path = \"C:/Users/frank/OneDrive/Desktop/GT_Practicum/data/preprocessed/AI+/malignant/img/\"\n",
    "json_des_path = \"C:/Users/frank/OneDrive/Desktop/GT_Practicum/data/preprocessed/AI+/malignant/json/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list.sort()\n",
    "json_list.sort()\n",
    "\n",
    "for img_path, json_path in zip(img_list, json_list):\n",
    "    assert os.path.basename(img_path)[:-4] == os.path.basename(json_path)[:-5]\n",
    "    img_des = os.path.join(img_des_path, os.path.basename(img_path))\n",
    "    json_des = os.path.join(json_des_path, os.path.basename(json_path))\n",
    "    shutil.copyfile(img_path, img_des)\n",
    "    shutil.copyfile(json_path, json_des)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decide Crop Size for Each Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding, need to manually divide the images to different batches based on their device brand (e.g., SonoScape).\n",
    "\n",
    "As images from different brand of scanners have different GUI layouts.\n",
    "\n",
    "Then crop images from each brand using same setups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"C:/Users/frank/OneDrive/Desktop/GT_Practicum/data/preprocessed/AI+/malignant/\"\n",
    "\n",
    "img_list = glob(os.path.join(data_path, './img/SonoScape/*.jpg'))\n",
    "json_folder = \"C:/Users/frank/OneDrive/Desktop/GT_Practicum/data/preprocessed/AI+/malignant/json/\"\n",
    "\n",
    "assert len(img_list) == len(json_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list.sort()\n",
    "# json_list.sort()\n",
    "\n",
    "dis_upper = []\n",
    "dis_lower = []\n",
    "dis_left = []\n",
    "dis_right = []\n",
    "\n",
    "# Measeure Distances of tumor rectangular box to image edges\n",
    "\n",
    "for img_path in img_list:\n",
    "    img = cv2.imread(img_path)\n",
    "    h, w, _ = img.shape\n",
    "    json_path = os.path.join(json_folder, os.path.basename(img_path)[:-4] + '.json')\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        for i in range(len(data['shapes'])):\n",
    "            dis_upper.append(data['shapes'][i]['points'][0][1])\n",
    "            dis_lower.append(h - data['shapes'][i]['points'][1][1])\n",
    "            dis_left.append(data['shapes'][i]['points'][0][0])\n",
    "            dis_right.append(w - data['shapes'][i]['points'][1][0])\n",
    "\n",
    "print(len(dis_upper))\n",
    "assert len(dis_upper) == len(dis_lower) == len(dis_left) == len(dis_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Minimum Distances to Crop from top for the image batch: {np.min(dis_upper)}\")\n",
    "print(f\"Minimum Distances to Crop from bottom for the image batch: {np.min(dis_lower)}\")\n",
    "print(f\"Minimum Distances to Crop from left for the image batch: {np.min(dis_left)}\")\n",
    "print(f\"Minimum Distances to Crop from right for the image batch: {np.min(dis_right)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop Images by Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_path = \"C:/Users/frank/OneDrive/Desktop/GT_Practicum/data/preprocessed/AI+/malignant/crop_img/SonoScape/\"\n",
    "\n",
    "for img_path in img_list:\n",
    "    img = cv2.imread(img_path)\n",
    "    img_crop = img[110:-180, 330:-210, :]\n",
    "    # img_crop = img\n",
    "    new_img_path = os.path.join(new_data_path, os.path.basename(img_path))\n",
    "    cv2.imwrite(new_img_path, img_crop)\n",
    "\n",
    "    json_path = os.path.join(json_folder, os.path.basename(img_path)[:-4] + '.json')\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    for i in range(len(data['shapes'])):\n",
    "        data['shapes'][i]['label'] = 'malignant'\n",
    "        data['shapes'][i]['points'][0][0] = data['shapes'][i]['points'][0][0] - 330\n",
    "        data['shapes'][i]['points'][1][0] = data['shapes'][i]['points'][1][0] - 330\n",
    "        data['shapes'][i]['points'][0][1] = data['shapes'][i]['points'][0][1] - 110\n",
    "        data['shapes'][i]['points'][1][1] = data['shapes'][i]['points'][1][1] - 110\n",
    "\n",
    "    data['imageHeight'] = img_crop.shape[0]\n",
    "    data['imageWidth'] = img_crop.shape[1]\n",
    "    data['imageData'] = None\n",
    "\n",
    "\n",
    "    new_json_path = os.path.join(new_data_path, os.path.basename(img_path)[:-4] + '.json')\n",
    "    with open(new_json_path, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
